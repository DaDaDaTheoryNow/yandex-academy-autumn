## Постановка задачи и начальные трудности

Задача бинарной классификации deepfake изображений характеризовалась крайним дисбалансом классов: **41,500 реальных изображений (класс 0) против 8,500 дипфейков (класс 1)**, соотношение **~5:1**. Базовые CNN модели демонстрировали систематические проблемы:

```
┌── Переобучение на доминирующий класс (предсказания → 100% класс 0)
├── Угасание градиентов при глубоких архитектурах
├── Недостаточная извлекаемость пространственных признаков
└── Шум «соль и перец» на изображениях
```

## Этап 1: Эксперименты с гибридной архитектурой

Была разработана гибридная модель Xception+FreqNet+Transformer, которая должна была покрыть все возможные гипотезы о выделении признаков:

**Архитектура:**

```
├── Xception CNN (depthwise separable conv + residuals)
├── FreqNet (FFT анализ артефактов)
├── CLS Token Transformer (глобальный контекст)
└── Skip connections: FreqNet → CNN патчи → Transformer
```

**Проблемы подхода:**

- На тот момент использовался MedianBlur, а он мог потенциально затирать частотные артефакты для FreqNet
- Недостаточное количество параметров (~5M)
- Отсутствие сильных гипотез для дальнейшей оптимизации
- Попытки решить всë и вся, вместо выделения конкретного способа

**Результат:** F1-score ~0.75, архитектура признана нежизнеспособной.

## Этап 2: Эксперименты с частотным анализом и предобработкой

После неудачи гибридной архитектуры был проведен глубокий анализ различных подходов к решению задачи, включая частотный анализ, методы балансировки классов и влияние предобработки данных.

### Частотный анализ для выявления паттернов сгенерированных изображений

**Гипотеза:** Изображения в датасете очень сложно классифицировать на глаз, скорее всего сгенерированность могут выдать только максимально мелкие детали. Применение частотного преобразования Фурье (FFT) позволяет получить частотную картину пиксельного изображения. Вырезав из диапазона частот низкие частоты, мы оставляем в частотной картине только мелкие детали.

**Архитектура FreqNet:**

```
├── Residual блоки для извлечения пространственных признаков
├── Частотные слои между Res-блоками (FFT преобразование)
├── Фильтрация низких частот для выделения мелких деталей
└── Обучение частотных паттернов сгенерированных/реальных изображений
```

**Результаты:**

- Модель на ~2M параметров с учетом дисбаланса классов: **F1-score = 0.48**
- Вывод: Частотный анализ оказался неэффективным на данном датасете
- Возможные причины: потеря критических признаков при частотной фильтрации, недостаточная ёмкость модели

### Исследование методов балансировки классов

Были исследованы три подхода к учету дисбаланса классов (5:1):

**1. Аугментация меньшего класса**

```
Проблема: Детали на сгенерированном изображении очень легко теряются
         при аугментации, что опасно для сохранения диагностических признаков
Вывод: Неприемлемо
```

**2. Срезание преобладающего класса**

```
Проблема: Уменьшит и без того небольшой датасет
Вывод: Неприемлемо
```

**3. Взвешенная функция потерь** ✅

```
Решение: Weighted CrossEntropyLoss с весами [0.6024, 2.9412]
Преимущества: Не требует изменения данных, эффективно компенсирует дисбаланс
Вывод: Наиболее приемлемый вариант
```

**Критическое наблюдение:** Без учета баланса классов модель вырождается в константную (всегда предсказывает доминирующий класс).

### Исследование влияния предобработки на поведение моделей

**Ключевое наблюдение:** Очень опасно применять какую-либо предобработку для такого датасета. Модели начинают обучаться намного медленнее, что объясняется **утерей критических данных**. Аугментация в данном случае требует подробнейшего исследования, так как может стирать столь чувствительные признаки.

**Эксперименты:**

**1. ResNet-50 без предобработки (30 эпох)**

- Базовый подход без предобработки
- Результат: Стабильное обучение - F1-score = 0.87

**2. ResNet-50 с выборочным маскированным блюром**

- Применение selective masked blur
- Результат: **Заметное ухудшение показателей, F1-score = ~0.3**
- Вывод: Даже выборочная предобработка опасна для сохранения признаков

**Выводы:**

- Предобработка должна быть **минимальной и селективной**
- Глобальные фильтры (например, MedianBlur) стирают диагностические артефакты
- Необходим подход, который удаляет только шум, сохраняя важные детали

### Сравнение моделей: FreqNet vs классические CNN

**Сравнение:**

- **FreqNet:** ~2M параметров, F1 = 0.48
- **ResNet:** Значительно больше параметров, лучшие результаты

**Ограничения сравнения:**

- Сравнение не совсем корректное из-за разницы в количестве параметров
- ResNet просто лучше запоминает датасет благодаря большей емкости

**Вывод:** Частотный анализ на данном датасете показал неэффективность, что привело к отказу от этого подхода в пользу классических сверточных архитектур.

## Этап 3: Переход к XceptionResNet50 (наш state of the art)

Тут нам стала известна информация о топе leaderboard-а (fine-tuned ResNet50), также проанализировав исследования об Xception и её эффективности по сравнению с обычными Inception была разработана новая модель. **XceptionResNet50** — гибридная архитектура, объединяющая эффективность depthwise separable convolutions с преимуществами residual connections.

### Архитектурные детали

**Базовый блок: DepthwiseSeparableConv**

```python
├── Depthwise convolution (groups=in_channels, kernel=3×3)
├── BatchNorm + ReLU
├── Pointwise convolution (1×1)
└── BatchNorm
```

**Основной блок: XceptionResNetBlock** (аналог Bottleneck из ResNet50)

```python
├── Conv1: DepthwiseSeparableConv(in → mid_channels, stride)
├── Conv2: DepthwiseSeparableConv(mid → mid_channels, stride=1)
├── Conv3: DepthwiseSeparableConv(mid → out_channels, stride=1)
└── Shortcut: 1×1 conv + BN (если stride≠1 или in_channels≠out_channels)
```

**Полная архитектура XceptionResNet50:**

```
Stem:
├── Conv2d(3→64, kernel=7×7, stride=2)
├── BatchNorm2d(64)
├── ReLU(inplace=True)
└── MaxPool2d(3×3, stride=2)

4 основных слоя:
├── Layer1: 256 channels, 3 блока (stride=1)
├── Layer2: 512 channels, 4 блока (stride=2)
├── Layer3: 1024 channels, 6 блоков (stride=2)
└── Layer4: 2048 channels, 3 блока (stride=2)

Head:
├── AdaptiveAvgPool2d(1×1)
├── Flatten
└── Linear(2048 → num_classes=2)
```

**Параметры модели:**

- **Всего параметров:** 13,679,746 (~13.7M)
- **Размер модели:** 52.18 MB (float32)
- **FLOPs:** ~65% от стандартного ResNet50
- **Память:** ~47MB vs 98MB у ResNet50

**Преимущества архитектуры:**

- **Эффективность:** Depthwise separable convolutions снижают вычислительную сложность
- **Стабильность:** Residual connections предотвращают затухающие/взрывающиеся градиенты + уменьшают симметрию параметрического пространства
- **Обобщение:** Depthwise conv лучше захватывает локальные паттерны артефактов
- **Масштабируемость:** Bottleneck структура (mid_channels = out_channels // 4) экономит параметры

## Этап 4: Обработка дисбаланса и шумов

### Взвешенная функция потерь

Для компенсации дисбаланса классов используется **Weighted CrossEntropyLoss**:

```python
class_weights = torch.tensor([total / (2 * count) for count in class_counts])
# Результат: [0.6024, 2.9412] для соотношения 5:1
loss_fn = nn.CrossEntropyLoss(weight=class_weights)
```

### Обработка шумов: эволюция методов

**Этап 1: Общий медианный фильтр (General Median Filter)**

- **Метод:**  
  Изначально применялся глобальный медианный фильтр ко всему изображению для подавления шума.

- **Проблема:**  
  Метод приводил к снижению итоговых метрик модели в среднем на 0.2 единицы.

- **Гипотеза:**  
  Фильтр сглаживал не только шум, но и высокочастотные паттерны генерации нейросетей (артефакты апсемплинга), из-за чего модели было сложнее корректно определять класс дипфейка.

**Этап 2: Избирательный фильтр с толерантностью (Selective Filter with Tolerance)**

- **Анализ шума:**  
  Датасет был зашумлен алгоритмом salt & pepper. При этом значения шумовых пикселей были не строго 0 или 255, а с погрешностью (примерно 5 и 250).

- **Решение:**  
  Разработан избирательный фильтр с параметром толерантности, который позволял детектировать шумовые пиксели, выбивающиеся из общего распределения, даже если они не были абсолютно черными или белыми.

**Этап 3: Объединённый фильтр (Combined Channel Masking / CoherentNoiseFilter)**

- **Финализация:**  
  Маски шума из всех трех цветовых каналов (R, G, B) были объединены.

- **Результат:**  
  Это устранило цветовые артефакты, возникавшие при наличии шума только в одном канале, и позволило сформировать корректную карту очистки с сохранением текстур реального изображения.

- **Алгоритм:**
   ```python
   ├── Детекция контрастирующих пикселей (tolerance=30)
   │   ├── Маска: (pixel <= 30) | (pixel >= 225)
   │   └── Применяется к каждому RGB каналу отдельно
   ├── Selective median filter (только шумовые области)
   │   └── Median filter 3×3 применяется только к маске
   └── Сохранение текстур реальных объектов
      └── Остальные пиксели остаются без изменений
   ```

**Ключевое преимущество:** Selective filtering сохраняет диагностические артефакты deepfake, удаляя только coherent noise (зернистый шум в тенях/светах). Главное преимущество этого подхода — отсутствие затерания важных артефактов изображения median blur'ом.

### Конфигурация обучения

```python
IMG_SIZE = 196
BATCH_SIZE = 32
NUM_EPOCHS = 25 x 3
LEARNING_RATE = 1e-3

Оптимизатор:
├── AdamW (lr=1e-3, weight_decay=1e-3)
└── ReduceLROnPlateau (factor=0.5, patience=2)

Аугментации:
├── Train: Resize(196×196) + CoherentNoiseFilter + RandomHorizontalFlip(0.5)
└── Val: Resize(196×196) + CoherentNoiseFilter
```

## Результаты обучения

### Прогресс обучения

```
20 эпох:        F1 = 0.87
25 эпох:       F1 = 0.91 (лучший результат)
40+ эпох:      F1 = 0.91
```

### Итоговые результаты

1. **Дисбаланс 5:1 → F1=0.91**
2. **Эффективная архитектура:** 13.7M параметров vs 25M+ у соперников
3. **Стабильные градиенты** благодаря residual + **Эффективные вычесления** на основе depthwise conv
4. **Noise-robust:** CoherentNoiseFilter критически важен для качества

### Что не успели, но стоило сделать

1. **Ensemble** моделей с разными архитектурами  
   Смешивание предсказаний (например, soft-voting) для повышения стабильности и качества на сложных примерах.

2. Псевдолейблинг на тестовых данных (semi-supervised)  
   Почему стоит рассмотреть? Мы проверели небольшие исследования насчëт уверенности в ответах нашей модели:

   - Доля «уверенных» примеров: 95.5% (9553/10000).
   - Средняя уверенность на отобранных: P (mean) = 0.987.
   - Дисбаланс псевдо-лейблов 85%:15% совпадает с train, что снижает риск selection bias.
   - Ожидаемая чистота меток >97%, поэтому добавление псевдо-лейблов выглядит оправданным.

3. Frequency-aware filtering для предобработки (FFT + Wiener filter)  
   Акцент на высоких частотах поможет выявить где проявляются мелкие артефакты синтеза (швы, неестественная текстура, следы апсемплинга).

## Вывод

Модель на основе **XceptionResNet50 + CoherentNoiseFilter** решила поставленную задачу классификации в условиях экстремального дисбаланса (5:1), достигнув **F1-score = 0.91**.

## Использование

### Обучение + инференс

```bash
python3 main.py --mode with_training
```

### Только инференс

```bash
python3 main.py --mode only_inference
```

**_Модель загружается из `release-weights.pth` (указано в `config.py`)._**
